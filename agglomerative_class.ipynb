{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot_Opinion_Distribution_2d(data1, data2, data_act):\n",
    "    op1_list = data1\n",
    "    op2_list = data2\n",
    "\n",
    "    fig, ax = plt.subplots(1,3, figsize=(12,4))\n",
    "    ax[0].set_title(\"Topic 1\")\n",
    "    ax[0].set_xlabel(\"Opinion\")\n",
    "    ax[0].set_ylabel(\"# of Opinions on Topic 1\")\n",
    "    ax[0].hist(op1_list, bins=60, density=True)\n",
    "    ax[1].set_title(\"Topic 2\")\n",
    "    ax[1].set_xlabel(\"Opinion\")\n",
    "    ax[1].set_ylabel(\"# of Opinions on Topic 2\")\n",
    "    ax[1].hist(op2_list, bins=60, density=True)\n",
    "    ax[2].set_title(\"Opinion-Space\")\n",
    "    ax[2].set_xlabel(\"Opinion 1\")\n",
    "    ax[2].set_ylabel(\"Opinion 2\")\n",
    "    ax[2].scatter(op1_list, op2_list, c=data_act, cmap='cool', marker = '2')\n",
    "    plt.show()\n",
    "\n",
    "def Agglomerative_Algorithm(data, thresh, runtime, min_nodes):\n",
    "    # get number of nodes\n",
    "    N = len(data[0])\n",
    "    # Declare needed array\n",
    "    nodes = np.empty((N,3))\n",
    "\n",
    "    # Fill node array. Last entry is the number of agglom. nodes, first two\n",
    "    # are the opinion of the node. Last one is its index\n",
    "    for i in range(N):\n",
    "        nodes[i][0] = data[len(data)-2][i]\n",
    "        nodes[i][1] = data[len(data)-1][i]\n",
    "        nodes[i][2] = 1\n",
    "\n",
    "    node_count = N\n",
    "\n",
    "    final_nodes = []\n",
    "\n",
    "    # Avoid cases where all nodes are cut off, which results in an empty array\n",
    "    # of final_nodes which results in an error for the classifier\n",
    "    while len(final_nodes) == 0:\n",
    "\n",
    "        # Start simulations\n",
    "        t = 0\n",
    "        while t < runtime:\n",
    "            # Create current index array\n",
    "            inds = np.arange(0, len(nodes), 1, dtype=int)\n",
    "\n",
    "            # Prepare arrays that save newly created nodes and the ones that were \n",
    "            # deleted in the iteration\n",
    "            nodes_new = []\n",
    "            deletes = []\n",
    "\n",
    "            for i in range(len(nodes)):\n",
    "                # Skip nodes that were merged\n",
    "                if (i in inds) == True and len(inds)>1:\n",
    "                    # Make sure that the loop stops if all nodes were merged.\n",
    "                    # Loop only continues if atleast 2 nodes are left to be merged\n",
    "                    if node_count > 1:\n",
    "                        # Pick random entry of nodes\n",
    "                        rand = i\n",
    "                        while rand == i or rand == -1:\n",
    "                            rand = np.random.choice(inds)\n",
    "                            rand_node = nodes[rand]\n",
    "\n",
    "                        # Calculate opinion distance\n",
    "                        op_dist = np.sqrt( (rand_node[0]-nodes[i][0])**2 + (rand_node[1]-nodes[i][1])**2 )\n",
    "                        # Implement threshold\n",
    "                        if op_dist < thresh:\n",
    "\n",
    "                            # Delete used nodes from indice index\n",
    "                            count = []\n",
    "                            for j in range (len(inds)):\n",
    "                                if inds[j] == i or inds[j] == int(rand):\n",
    "                                    count.append(j)\n",
    "                            inds = np.delete(inds, count)\n",
    "\n",
    "                            deletes.append(i, int(rand))\n",
    "                                    \n",
    "                            # Extract numbers of nodes\n",
    "                            n1 = int(nodes[i][2])\n",
    "                            n2 = int(rand_node[2])\n",
    "                            # Calculate and append new opinions and number of agglom. nodes\n",
    "                            avr1 = ( n1*nodes[i][0] + n2*rand_node[0]) / (n1+n2)\n",
    "                            avr2 = ( n1*nodes[i][1] + n2*rand_node[1]) / (n1+n2)\n",
    "                            n = n1+n2\n",
    "                            nodes_new.append( [avr1, avr2, n] )\n",
    "                            node_count -= 1\n",
    "                    else:\n",
    "                        # Stop loop if not enough nodes are left to be merged.\n",
    "                        break\n",
    "\n",
    "            # Delete old nodes\n",
    "            nodes = np.delete( nodes, deletes, axis=0 )\n",
    "\n",
    "            # Append new nodes to nodes array\n",
    "            \n",
    "            if nodes_new != []:\n",
    "                nodes = np.append(nodes, nodes_new, axis=0)\n",
    "        \n",
    "            t += 1\n",
    "\n",
    "        # Only return nodes with #nodes >= min_nodes\n",
    "        final_nodes = []\n",
    "        for i in range (len(nodes)):\n",
    "            if nodes[i][2] >= min_nodes:\n",
    "                final_nodes.append( nodes[i] )\n",
    "        final_nodes = np.array( final_nodes )\n",
    "    \n",
    "    # return last list only containing opinion and number of nodes\n",
    "    return final_nodes\n",
    "\n",
    "#@njit\n",
    "def Count(data, counts, num_aggs, i, j, k):\n",
    "    for l in range (num_aggs):\n",
    "        print(f\"i: {i};\\tj: {j};\\tk: {k}\\tl: {l}\")\n",
    "        # Perform algorithm until 1 <= #nodes <= 5\n",
    "        num_nodes = 6\n",
    "        while num_nodes > 5 or num_nodes == 0:\n",
    "            last_nodes = Agglomerative_Algorithm(data, 2.5, 100, 250)\n",
    "            num_nodes = len( last_nodes )\n",
    "        # Classify case\n",
    "        if num_nodes == 1:\n",
    "            counts[0] += 1\n",
    "        if num_nodes == 2:\n",
    "            counts[2] += 1\n",
    "        if num_nodes == 4:\n",
    "            counts[1] += 1\n",
    "        if num_nodes == 5:\n",
    "            counts[1] += 1\n",
    "        # Special case of 3 nodes, since often problems at the phaseshift between \n",
    "        # Consensus and ideology happen\n",
    "        if num_nodes == 3:\n",
    "            # Sort nodes from smallest to biggest. If the biggest is bigger than \n",
    "            # the first and second nodes the big one usually sits in the middle,\n",
    "            # which generally happens at consensus\n",
    "            last_nodes = last_nodes[np.argsort( last_nodes[:,2] )]\n",
    "            if last_nodes[0][2] + last_nodes[1][2] < last_nodes[2][2]:\n",
    "                counts[0] += 1\n",
    "            else:\n",
    "                counts[2] += 1\n",
    "\n",
    "\n",
    "def Agglomerative_Classifier(frac, sims, num_aggs):\n",
    "\n",
    "    if num_aggs % 2 == 0:\n",
    "        print(\"ERROR! Uneven number of agglomerative runs is needed.\\n\")\n",
    "        return 0\n",
    "\n",
    "    alphas = np.arange(0.0, 4.1, 0.1)\n",
    "    cosds = np.arange(0.0, 1.1, 0.1)\n",
    "\n",
    "    saves = np.zeros((len(alphas), len(cosds)))\n",
    "\n",
    "    for i in range(len(alphas)):\n",
    "        for j in range(len(cosds)):\n",
    "            \n",
    "            # Count wether algorithm says dataset is consensus, polarization or ideology\n",
    "            # First entry is cons-counter, 2nd polarization and 3rd ideology\n",
    "            counts = np.zeros(3, dtype=int)\n",
    "            for k in range(sims):\n",
    "\n",
    "                # Load data\n",
    "                df = pd.read_csv(f'D:\\Daten mit Änderungen\\Physik\\Bachelorarbeit\\Generated_Data\\Bound\\Phase\\\\a{alphas[i]:.1f}_b5.0_cosd{cosds[j]:.1f}_frac_{frac:.1f}_{k+1}.csv', header = None)\n",
    "                data = df.to_numpy()\n",
    "                # Number of nodes\n",
    "                N = len(data[0])\n",
    "                # Neglect nodes that stay around zero.\n",
    "                sorts = np.argsort( data[0] )\n",
    "                # Transpose to access nodes\n",
    "                sorted = data.T[sorts]\n",
    "                Num = int(N * (1-frac))\n",
    "                # Transpose back\n",
    "                data = sorted[:Num].T\n",
    "\n",
    "                Count(data, counts, num_aggs, i, j, k)\n",
    "                \n",
    "            saves[i][j] = np.argmax(counts)\n",
    "\n",
    "    pd.DataFrame(saves).to_csv(f\"D:\\Daten mit Änderungen\\Physik\\Bachelorarbeit\\Generated_Data\\Bound\\Heatmap_frac{frac}.csv\", index = False, header = False)\n",
    "    return saves\n",
    "                    \n",
    "\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = Agglomerative_Classifier(0.0, 1, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying out for single datasets\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(f'D:\\Daten mit Änderungen\\Physik\\Bachelorarbeit\\Generated_Data\\Bound\\Phase\\\\a2.0_b5.0_cosd0.0_frac_0.2_1.csv', header = None)\n",
    "data = df.to_numpy()\n",
    "\n",
    "N = len(data[0])\n",
    "\n",
    "# Exclude bounded nodes\n",
    "frac = 0.2\n",
    "# Neglect nodes that stay around zero.\n",
    "sorts = np.argsort( data[0] )\n",
    "#print(sorts)\n",
    "# Transpose to access nodes\n",
    "sorted = data.T[sorts]\n",
    "Num = int(N * (1-frac))\n",
    "# Transpose back\n",
    "data = sorted[:Num].T\n",
    "\n",
    "results = Agglomerative_Algorithm(data, 2.5, 100, 250)\n",
    "\n",
    "print(results)\n",
    "print(len(results))\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter( results[:,0], results[:,1] )\n",
    "plt.grid()\n",
    "Plot_Opinion_Distribution_2d(data[len(data)-2], data[len(data)-1], data[0])\n",
    "\n",
    "# Problems with classifying transmission from consens to ideology:\n",
    "# Often one or two more nodes beside the big one in the middle emerge.\n",
    "# Some cases can still be correctly classified when comparing the size and\n",
    "# using for example a size-difference of 500 to the node in the middle to\n",
    "# still classify the whole thing as consensus. Still, one or two paramter-\n",
    "# pairs will be missclassified."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ddb9d49f01c08b650b2475798d3b5b8f5fc430922bf05166bf85d448657af32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
